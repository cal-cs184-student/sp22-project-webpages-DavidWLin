<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>  
    div.padded {  
      padding-top: 0px;  
      padding-right: 100px;  
      padding-bottom: 0.25in;  
      padding-left: 100px;  
    }  
  </style> 
<title>Avni Jain and David Lin  |  CS 184</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="style.css" media="screen" />
</head>
<body>
<br />
<h1 align="middle">Assignment 3: PathTracer</h1>
    <h2 align="middle">Avni Jain and David Lin</h2>

    <div class="padded">
        <p>In this project, we implemented multiple aspects of the path tracing algorithm in order to render various scenes with lighting. Path tracing allows us to illuminate images with realistic lighting using ray intersection techniques. The algorithm determines how much of the illuminance from a light source will arrive at the viewpoint camera. We implemented triangle and sphere intersection algorithms which allowed us to figure out if and where a ray would form an intersection. We also constructed Bounding Volume Hierarchy (BVH) boxes to speed up the process of rendering images. A key part of this project is global illumination; we accomplished this using direct and indirect lighting functions. Lastly, we used adaptive sampling to reduce the noise in our rendered images. </p>

    <h2 align="middle">Part 1: Ray Generation and Intersection</h2>
        <p>We start this project by generating rays and seeing how we can intersect them with triangles and spheres. We are able to generate rays by taking normalized image coordinates and converting them into the world space. Rays are generated starting with the image coordinates which are first converted into the camera space, where the rays are generated, and then converted into the world space. 
Given a normalized image coordinate (x, y), we can map it to the camera space where we know the center, bottom left corner, and top right corner—which are in terms of the field of view angles along the X and Y axis. A ray in the camera space will start at the camera and intersect with the point on the sensor corresponding to (x, y). We then transformed this ray into the world space which includes transforming the origin and direction.
In order to convert the ray into the world space, we used the transformation matrix c2w which dictates the direction of the ray. The origin of the ray is simply the position of the camera, pos.  
</p>
	<p> The triangle intersection algorithm involves checking to see if there is an intersection between the ray and given triangle; it also provides the nearest intersection location. The algorithm Triangle::has_intersection(…) just checks to see if there is an intersection or not and returns a Boolean. The second algorithm, Triangle:intersect(…) is what checks for an intersection and reports the nearest intersection point. 
Our ray is parameterized by r(t) = O + tD for 0<= t < inf. If we have a triangle with the coordinates P0, P1, and P2, we can use Barycentric Coordinates to set a point P, where P = (1 – b1 – b2)*P0 + b1*P1 + b2*P2. The intersection of the ray and triangle can then be seen when we set r(t) = P. We used the Moller-Trombore algorithm to solve for t, b1, and b2. Once we perform the intersection of the ray and triangle, we return a Boolean depending on whether or not the intersection exists. If t is within the range [min_t, max_t], we know the intersection exists and we return True. If the intersection exists, we update max_t to t. Otherwise, we return False.  
We also implemented a ray-sphere intersection algorithm which checks to see if the ray intersects with some given sphere. The overall method is similar to that of the ray-triangle intersection algorithm except the equation for a sphere is different which changes the actual intersection. A sphere is parameterized by its center C and has a set of points P which satisfies (P-C)^2 – R^2 = 0. We solve for the intersection and find that t can essentially be solved using the quadratic formula. 
</p>
        <div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="cowwww.png" width="480px" />
                    <figcaption align="middle">Normal Shading for cow.dae</figcaption>
			    <td align="middle">
                    <img src="bunny.png" width="480px" />
                    <figcaption align="middle">Normal Shading for Bunny</figcaption>
                </tr>
		<tr>
                    <td align="middle">
                    <img src="Teapot.png" width="480px" />
                    <figcaption align="middle">Normal Shading for Teapot</figcaption>
                </tr>
            </table>
        </div>
        <p>Here is an example of how to include a simple formula:</p>
        <p align="middle"><pre align="middle">a^2 + b^2 = c^2</pre></p>
        
	
	
	<h2 align="middle">Part 2: Bounding Volume Hierarchy</h2>
        <p>We start this project by generating rays and seeing how we can intersect them with triangles and spheres. We are able to generate rays by taking normalized image coordinates and converting them into the world space. Rays are generated starting with the image coordinates which are first converted into the camera space, where the rays are generated, and then converted into the world space. 
Given a normalized image coordinate (x, y), we can map it to the camera space where we know the center, bottom left corner, and top right corner—which are in terms of the field of view angles along the X and Y axis. A ray in the camera space will start at the camera and intersect with the point on the sensor corresponding to (x, y). We then transformed this ray into the world space which includes transforming the origin and direction.
In order to convert the ray into the world space, we used the transformation matrix c2w which dictates the direction of the ray. The origin of the ray is simply the position of the camera, pos.  
</p>
	<p> The triangle intersection algorithm involves checking to see if there is an intersection between the ray and given triangle; it also provides the nearest intersection location. The algorithm Triangle::has_intersection(…) just checks to see if there is an intersection or not and returns a Boolean. The second algorithm, Triangle:intersect(…) is what checks for an intersection and reports the nearest intersection point. 
Our ray is parameterized by r(t) = O + tD for 0<= t < inf. If we have a triangle with the coordinates P0, P1, and P2, we can use Barycentric Coordinates to set a point P, where P = (1 – b1 – b2)*P0 + b1*P1 + b2*P2. The intersection of the ray and triangle can then be seen when we set r(t) = P. We used the Moller-Trombore algorithm to solve for t, b1, and b2. Once we perform the intersection of the ray and triangle, we return a Boolean depending on whether or not the intersection exists. If t is within the range [min_t, max_t], we know the intersection exists and we return True. If the intersection exists, we update max_t to t. Otherwise, we return False.  
We also implemented a ray-sphere intersection algorithm which checks to see if the ray intersects with some given sphere. The overall method is similar to that of the ray-triangle intersection algorithm except the equation for a sphere is different which changes the actual intersection. A sphere is parameterized by its center C and has a set of points P which satisfies (P-C)^2 – R^2 = 0. We solve for the intersection and find that t can essentially be solved using the quadratic formula. 
</p>
	<h4>Normal Shading for large .dae files that can only be rendered with BVH Acceleration</h4> 
        <div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="maxplanck.png" width="480px" />
                    <figcaption align="middle">Maxplanck</figcaption>
			    
			    <td align="middle">
                    <img src="CBlucy.png" width="480px" />
                    <figcaption align="middle">Lucy</figcaption>
                </tr>
            </table>
        </div>
	
	
	
	<h2 align="middle">Part 3: Direct Illumination</h2>
        <p> We implemented two different direct lighting functions: direct lighting with uniform hemisphere sampling and direct lighting by importance sampling lights. In direct lighting with uniform hemisphere sampling, we sample uniformly from the hemisphere and estimate the intersection coming directly from the light. In our method, we sampled the light coming into the point w_in and converted those rays to the world space using our transformation matrix o2w. We then created a new intersect struct and shadow ray such that the origin is at the hit point and the direction is wi_world. If the shadow has an intersection at any point, we run get_emission() use an equation to find the output.  
In direct lighting by importance sampling, our goal is to increase efficiency by sampling from the light source directly. We first call SceneLight::sample_L() which takes a hit point and returns the incoming radiance. We also create a new shadow ray with the origin being the point and direction being wi. If the shadow ray does not intersect anything, then we will set a temp vector to radiance*fr*cos_theta(wi) and divide that by the pdf due to the light sampling distribution bias. We then return Lout which is the light that is outputted. 

</p>
        <div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="images/example_image.png" width="480px" />
                    <figcaption align="middle">Spheres </figcaption>
                </tr>
            </table>
        </div>
	
	
	
	<h2 align="middle">Part 4: Global Illumination</h2>
        <p> The indirect lighting function allows us to render images with global illumination, in combination with direct lighting which we implemented earlier. We utilize Russian Roulette in order to provide an unbiased estimate; currently, setting a maximum depth leads to a biased estimate which is what we are trying to avoid. We use the function est_radiance_global_illumination() which estimates the total radiance given some direction. We use zero_bounce_radiance, one_bounce_radiance, and at_least_one_bounce_radiance to return the light resulting from zero bounces, direct illumination, and indirect illumination, respectively. 
In this section, we focused on implementing at_least_one_bounce_radiance which is what gives us indirect illumination. To do that, we set a termination probability between 0.3 and 0.4 which we use later when determining whether or not we want to terminate the recursive call. We also need to ensure that there is at least one indirect ray intersection which is why we check if r.depth == max_ray_depth and subsequently recurse at_least_one_bounce_radiance.  

</p>
	
	
	<div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="4_3.png" width="480px" />
                    <figcaption align="middle">Global Illumination, 0 Bounces (1024 samples per pixel)</figcaption>
                <td align="middle">
                    <img src="4_4.png" width="480px" />
                    <figcaption align="middle">Global Illumination, 1 Bounce (1024 samples per pixel)</figcaption>
		    </tr>
            </table>
        </div>
	
	<div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="4_5.png width="480px" />
                    <figcaption align="middle">Global Illumination, 2 Bounces (1024 samples per pixel)</figcaption>
                    <td align="middle">
                    <img src="4_6.png" width="480px" />
                    <figcaption align="middle">Global Illumination, 3 Bounces (1024 samples per pixel)</figcaption>
		</tr>
		<tr>
                    <td align="middle">
                    <img src="4_7.png" width="480px" />
                    <figcaption align="middle">Global Illumination, 4 Bounces (1024 samples per pixel)</figcaption>
					      </tr>
					      </table>
					      </div>
	
	
	
	
	
        <div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="spheres_direct_only.png" width="480px" />
                    <figcaption align="middle">Spheres with Direct Illumination only (1024 samples per pixel)</figcaption>
                <td align="middle">
                    <img src="spheres_indirect_only.png" width="480px" />
                    <figcaption align="middle">Spheres with Indirect Illumination only (1024 samples per pixel)</figcaption>
		    </tr>
            </table>
        </div>
	
	<div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="spheres_sample1.png" width="480px" />
                    <figcaption align="middle">Global Illumination, 1 sample per pixel, 4 light rays, 5 bounces</figcaption>
                    <td align="middle">
                    <img src="spheres_sample2.png" width="480px" />
                    <figcaption align="middle">Global Illumination, 2 sample per pixel, 4 light rays, 5 bounces</figcaption>
		</tr>
		<tr>
                    <td align="middle">
                    <img src="spheres_sample4.png" width="480px" />
                    <figcaption align="middle">Global Illumination, 4 sample per pixel, 4 light rays, 5 bounces</figcaption>
                    <td align="middle">
                    <img src="spheres_sample8.png" width="480px" />
                    <figcaption align="middle">Global Illumination, 8 sample per pixel, 4 light rays, 5 bounces</figcaption>
		</tr>
		<tr>
                    <td align="middle">
                    <img src="spheres_sample16.png" width="480px" />
                    <figcaption align="middle">Global Illumination, 16 sample per pixel, 4 light rays, 5 bounces</figcaption>
                    <td align="middle">
                    <img src="spheres_sample64.png" width="480px" />
                    <figcaption align="middle">Global Illumination, 64 sample per pixel, 4 light rays, 5 bounces</figcaption>
		</tr>
		<tr>
                    <td align="middle">
                    <img src="spheres_1024_pixel.png" width="480px" />
                    <figcaption align="middle">Global Illumination, 1024 sample per pixel, 4 light rays, 5 bounces</figcaption>
		</tr>
            </table>
        </div>
	
	<h2 align="middle">Part 5: Adaptive Sampling</h2>
        <p> In this last part, we implemented adaptive sampling in order to reduce the noise that’s visible in images. We know that some pixels converge faster than others depending on the sampling rate. Adaptive sampling uses a large, fixed number of pixels by concentrating the pixels in the more difficult parts of the image. In our algorithm, we iterate through individual pixels and detect whether or not the pixel has converged. We do this by finding their mean and standard deviation; using the formula I = 1.96 * standard deviation/sqrt(n), we can figure out what the pixel’s convergence is. When I < maxTolerance * mean, we stop tracing more rays for that pixel.  
</p>
        <div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="bunny_adaptive.png" width="480px" />
                    <figcaption align="middle">2048 Samples per pixel, 64 samples per batch, 5 bounces</figcaption>
			    
			    <td align="middle">
                    <img src="bunny_adaptive_rate.png" width="480px" />
                    <figcaption align="middle">Showing Sampling rates for adaptive sampling</figcaption>
                </tr>
            </table>
        </div>
	
	
	
	

    <h2 align="middle">A Few Notes On Webpages</h2>
        <p>Here are a few problems students have encountered in the past. You will probably encounter these problems at some point, so don't wait until right before the deadline to check that everything is working. Test your website on the instructional machines early!</p>
        <ul>
        <li>Your main report page should be called index.html.</li>
        <li>Be sure to include and turn in all of the other files (such as images) that are linked in your report!</li>
        <li>Use only <em>relative</em> paths to files, such as <pre>"./images/image.jpg"</pre>
        Do <em>NOT</em> use absolute paths, such as <pre>"/Users/student/Desktop/image.jpg"</pre></li>
        <li>Pay close attention to your filename extensions. Remember that on UNIX systems (such as the instructional machines), capitalization matters. <pre>.png != .jpeg != .jpg != .JPG</pre>
        <li>Be sure to adjust the permissions on your files so that they are world readable. For more information on this please see this tutorial: <a href="http://www.grymoire.com/Unix/Permissions.html">http://www.grymoire.com/Unix/Permissions.html</a></li>
        <li>And again, test your website on the instructional machines early!</li>
</div>
</body>
</html>
